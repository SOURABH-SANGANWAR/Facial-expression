{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning model Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "neutral\n",
      "sad\n",
      "surprise\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "features=[]\n",
    "targets=[]\n",
    "path=\"D:/train/\"\n",
    "folders={\"angry\":0,\"disgust\":1,\"fear\":2,\"happy\":3,\"neutral\":4,\"sad\":5,\"surprise\":6}\n",
    "for i in folders:\n",
    "    C=os.listdir(path+str(i))\n",
    "    for j in C:\n",
    "        image=cv2.imread(path+str(i)+\"/\"+str(j))\n",
    "        try:\n",
    "            image=cv2.resize(image,(32,32))\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            features.append(image)\n",
    "            targets.append(folders[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "targets=np.array(targets)\n",
    "features=np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821, 32, 32, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_features,train_target)=(features,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Data into required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image=image/255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821, 32, 32, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features=np.array(list(map(preprocessing,train_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=train_features.reshape(28821, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821, 32, 32, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen=ImageDataGenerator(rotation_range=1,width_shift_range=0,height_shift_range=0,zoom_range=0,shear_range=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting targets to categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=to_categorical(train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "Model = Sequential()\n",
    "Model.add(Conv2D(64,(3,3), padding='same', input_shape=(32, 32,1)))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPooling2D((2, 2)))\n",
    "Model.add(Dropout(0.25))\n",
    "Model.add(Conv2D(128,(5,5), padding='same'))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPooling2D((2, 2)))\n",
    "Model.add(Dropout(0.25))\n",
    "Model.add(Conv2D(512,(3,3), padding='same'))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPooling2D((2, 2)))\n",
    "Model.add(Dropout(0.25))\n",
    "Model.add(Conv2D(512,(3,3), padding='same'))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(MaxPooling2D((2, 2)))\n",
    "Model.add(Dropout(0.25))\n",
    "Model.add(Flatten())\n",
    "Model.add(Dense(256))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(Dropout(0.5))\n",
    "Model.add(Dense(512))\n",
    "Model.add(BatchNormalization())\n",
    "Model.add(Activation('relu'))\n",
    "Model.add(Dropout(0.5))\n",
    "Model.add(Dense(14, activation='relu'))\n",
    "Model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "Model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading previous weights:\n",
    "#### ( Model is trained multiple times so that to run PC for less time continously and achive better accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.load_weights(\"AI_April-2021_SourabhSanganwar_facemodelweights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model:\n",
    "##### ( I had trained it many times in parts and loaded weights now iam training it for one epoch for illustration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442/1442 [==============================] - 267s 184ms/step - loss: 0.2895 - accuracy: 0.9009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17563f88f10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit_generator(datagen.flow(train_features,train_target,batch_size=20),epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model to file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2=Model.to_json()\n",
    "path=\"D:/modelData/facemodelarchitecture.json\"\n",
    "file_model=open(path,\"w\")\n",
    "file_model.write(model_2)\n",
    "file_model.close()\n",
    "Model.save_weights(\"D:/modelData/facemodelweights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding emotions using webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import model_from_json\n",
    "path=\"AI_April-2021_SourabhSanganwar_facemodelarchitecture.json\"\n",
    "modelfile=open(path,'r')\n",
    "Model=model_from_json(modelfile.read())\n",
    "modelfile.close()\n",
    "Model.load_weights(\"AI_April-2021_SourabhSanganwar_facemodelweights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up input from webcam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brightness=180\n",
    "capt=cv2.VideoCapture(0)\n",
    "capt.set(3,640)\n",
    "capt.set(4,480)\n",
    "capt.set(10,brightness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining functions and maps in prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)           \n",
    "    image=image/255                                        \n",
    "    return image\n",
    "emotions={0:\"Angry\",1:\"Disgust\",2:\"Fear\",3:\"Happy\",4:\"Neutral\",5:\"Sad\",6:\"Surprise\"}\n",
    "\n",
    "def max_index (a,b):\n",
    "    for i in range(0,7):\n",
    "        if a[0][i]==b:\n",
    "            return i\n",
    "colour={\"Angry\":(0,0,250),\"Disgust\":(0,255,255),\"Fear\":(255,255,0),\"Happy\":(0,255,0),\"Neutral\":(0,0,0),\"Sad\":(200,0,129),\"Surprise\":(129,64,18)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and showing image in webcam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final\n",
    "while True:\n",
    "    message,images=capt.read()\n",
    "    images=cv2.flip(images,1,0)\n",
    "    temp=np.asarray(images)\n",
    "    image=np.asarray(images)\n",
    "    face_cascade=cv2.CascadeClassifier(\"haarcascade.xml\")\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(image,1.1,4)\n",
    "    proba=0\n",
    "    Emotion=\" \"\n",
    "    Asc=0\n",
    "    for (x,y,w,h) in faces:\n",
    "        imag=images[x:x+w,y:y+h]\n",
    "        try:\n",
    "            imag=cv2.resize(imag,(32,32))\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            imag=preprocess(imag)\n",
    "            imag=imag.reshape(1,32,32,1)\n",
    "            lists=Model.predict(imag)\n",
    "            proba=lists[0]\n",
    "            proba=proba.max()\n",
    "            index=0\n",
    "            for i in range(0,7):\n",
    "                if lists[0][i]==proba:\n",
    "                    index=i\n",
    "                    break\n",
    "            Emotion=emotions[max_index(lists,proba)]\n",
    "        cv2.putText(images,\"Facial Expression Detector\",(100,30),cv2.FONT_HERSHEY_COMPLEX,1,(0,250,0),2)\n",
    "        if proba>0.6:\n",
    "            cv2.putText(images,Emotion,(x+int(2*w/200),y+int(30*w/200)),cv2.FONT_HERSHEY_SIMPLEX,1*w/200,colour[Emotion],2*w//300+1)\n",
    "        images=cv2.rectangle(images,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "    cv2.putText(images,\"Facial Expression Detector\",(100,30),cv2.FONT_HERSHEY_COMPLEX,1,(0,250,0),2)\n",
    "    cv2.imshow(\"ModelPrediction\",images)\n",
    "    Asc=cv2.waitKey(20)\n",
    "    if Asc==ord(\"e\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
